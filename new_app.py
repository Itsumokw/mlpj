import streamlit as st
import torch
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler
import time

# è®¾ç½®é¡µé¢å¸ƒå±€
st.set_page_config(layout="wide", page_title="ARIMA Time Series Forecasting")
st.title("âœˆï¸ Air Passengers Forecasting with Neural ARIMA")
st.markdown("""
This application demonstrates a neural network-based ARIMA model for forecasting monthly airline passengers.
The model incorporates both autoregressive (AR) and moving average (MA) components, along with seasonal features.
""")

# ä¾§è¾¹æ é…ç½®
with st.sidebar:
    st.header("âš™ï¸ Model Configuration")

    # æ¨¡å‹å‚æ•°
    p = st.slider("AR Order (p)", 1, 24, 12, 1,
                  help="Number of lag observations included in the model (autoregressive part)")
    q = st.slider("MA Order (q)", 1, 12, 1, 1,
                  help="Size of the moving average window")
    hidden_size = st.slider("Hidden Layer Size", 16, 128, 64, 16)
    lr = st.slider("Learning Rate", 0.001, 0.1, 0.005, 0.001)
    epochs = st.slider("Training Epochs", 100, 2000, 500, 100)
    alpha = st.slider("MA Loss Weight (Î±)", 0.01, 0.5, 0.1, 0.01,
                      help="Weight for moving average component in loss function")

    # æ•°æ®é€‰é¡¹
    show_data = st.checkbox("Show Raw Data", True)
    show_diff = st.checkbox("Show Differenced Data", False)

    st.subheader("Forecasting Options")
    forecast_months = st.slider("Months to Forecast", 1, 24, 12, 1)

    train_button = st.button("ğŸš€ Train Model")


# åŠ è½½æ•°æ®
@st.cache_data
def load_data():
    try:
        data = pd.read_csv('datasets/rakannimer/air-passengers/versions/1/AirPassengers.csv')
        passengers = data['#Passengers'].values.astype(float)
        months = [int(m.split('-')[1]) for m in data['Month']]
        return data, passengers, months
    except:
        st.error("Failed to load data. Using sample data instead.")
        # Generate sample data if file not found
        t = np.arange(0, 100)
        passengers = 100 + 50 * np.sin(0.1 * t) + 30 * np.random.randn(100)
        months = [i % 12 + 1 for i in range(100)]
        data = pd.DataFrame({'Month': [f"1949-{m:02d}" for m in months], '#Passengers': passengers})
        return data, passengers, months


data, passengers, months = load_data()

# æ˜¾ç¤ºåŸå§‹æ•°æ®
if show_data:
    st.subheader("ğŸ“Š Air Passengers Data")
    col1, col2 = st.columns([1, 2])
    with col1:
        st.dataframe(data.head(10))
    with col2:
        fig, ax = plt.subplots(figsize=(10, 4))
        ax.plot(data['Month'], data['#Passengers'], 'b-')
        ax.set_title("Monthly Air Passengers (1949-1960)")
        ax.set_xlabel("Date")
        ax.set_ylabel("Passengers")
        ax.grid(True)
        plt.xticks(rotation=45)
        st.pyplot(fig)


# æ•°æ®é¢„å¤„ç†å‡½æ•°
def preprocess_data(passengers, months, p, q, s=12):
    """Preprocess data for ARIMA model"""

    # å·®åˆ†æ“ä½œå‡½æ•°
    def difference(data, interval=1):
        return [data[i] - data[i - interval] for i in range(interval, len(data))]

    # åŸå§‹æ•°æ®
    original = passengers.copy()

    # ä¸€é˜¶å·®åˆ†
    diff1 = difference(passengers, 1)
    # å­£èŠ‚æ€§å·®åˆ†
    diff_seasonal = difference(diff1[s:], s)

    # æ›´æ–°æœˆä»½ä¿¡æ¯ä»¥åŒ¹é…å·®åˆ†åçš„æ•°æ®
    months_diff = months[s + 1:]

    # åˆ›å»ºæœˆä»½ç‰¹å¾çŸ©é˜µ (one-hotç¼–ç )
    def create_month_features(months):
        month_features = np.zeros((len(months), 12))
        for i, month in enumerate(months):
            month_features[i, month - 1] = 1
        return month_features

    month_features = create_month_features(months_diff)

    # æ•°æ®å½’ä¸€åŒ–
    scaler = MinMaxScaler(feature_range=(-1, 1))
    diff_seasonal_normalized = scaler.fit_transform(np.array(diff_seasonal).reshape(-1, 1)).flatten()

    # åˆ›å»ºæ•°æ®é›†å‡½æ•°
    def create_dataset(data, month_features, p, q):
        X, y = [], []
        errors = []  # å­˜å‚¨é¢„æµ‹è¯¯å·®
        for i in range(p, len(data)):
            # ARç‰¹å¾: è¿‡å»pä¸ªå€¼
            ar_features = data[i - p:i]

            # MAç‰¹å¾: è¿‡å»qä¸ªé¢„æµ‹è¯¯å·®
            ma_features = errors[-q:] if len(errors) >= q else [0] * q

            # å­£èŠ‚æ€§ç‰¹å¾: å½“å‰æœˆä»½
            seasonal_feature = month_features[i]

            # åˆå¹¶æ‰€æœ‰ç‰¹å¾
            features = np.concatenate((ar_features, ma_features, seasonal_feature))
            X.append(features)
            y.append(data[i])

            # è®¡ç®—å½“å‰é¢„æµ‹è¯¯å·®
            if len(errors) < 10:  # åˆå§‹é˜¶æ®µ
                errors.append(0)
            else:
                # å®é™…å€¼å‡å»ç‰¹å¾çš„å¹³å‡å€¼ä½œä¸ºè¯¯å·®ä¼°è®¡
                errors.append(data[i] - np.mean(features[:p]))

        return np.array(X), np.array(y)

    X, y = create_dataset(diff_seasonal_normalized, month_features, p, q)

    # è½¬æ¢ä¸ºPyTorchå¼ é‡
    X = torch.tensor(X, dtype=torch.float32)
    y = torch.tensor(y, dtype=torch.float32).unsqueeze(-1)

    # æ•°æ®é›†åˆ’åˆ†
    train_size = int(len(X) * 0.8)
    X_train, X_test = X[:train_size], X[train_size:]
    y_train, y_test = y[:train_size], y[train_size:]

    return {
        'original': original,
        'months': months,
        'months_diff': months_diff,
        'scaler': scaler,
        'X_train': X_train,
        'X_test': X_test,
        'y_train': y_train,
        'y_test': y_test,
        'train_size': train_size,
        'p': p,
        'q': q
    }


# å®šä¹‰ARIMAæ¨¡å‹
class ARIMAModel(torch.nn.Module):
    def __init__(self, input_size, hidden_size, output_size):
        super().__init__()
        self.fc1 = torch.nn.Linear(input_size, hidden_size)
        self.fc2 = torch.nn.Linear(hidden_size, hidden_size)
        self.fc3 = torch.nn.Linear(hidden_size, output_size)
        self.relu = torch.nn.ReLU()

    def forward(self, x):
        x = self.relu(self.fc1(x))
        x = self.relu(self.fc2(x))
        x = self.fc3(x)
        return x


# è‡ªå®šä¹‰æŸå¤±å‡½æ•°
class MALoss(torch.nn.Module):
    def __init__(self, q=1, alpha=0.1):
        super().__init__()
        self.q = q
        self.alpha = alpha
        self.mse = torch.nn.MSELoss()

    def forward(self, predictions, targets, model_errors):
        mse_loss = self.mse(predictions, targets)
        ma_loss = torch.tensor(0.0, device=predictions.device)

        if len(model_errors) >= self.q:
            recent_errors = model_errors[-self.q:]
            ma_loss = torch.mean(recent_errors ** 2)

        total_loss = mse_loss + self.alpha * ma_loss
        return total_loss


# è®­ç»ƒæ¨¡å‹
def train_model(model, X_train, y_train, criterion, optimizer, epochs):
    losses = []
    device = X_train.device
    model_errors = torch.tensor([], device=device)

    progress_bar = st.progress(0)
    status_text = st.empty()

    for epoch in range(epochs):
        model.train()
        optimizer.zero_grad()

        # å‰å‘ä¼ æ’­
        outputs = model(X_train)

        # è®¡ç®—å½“å‰æ‰¹æ¬¡çš„è¯¯å·®
        batch_errors = (outputs - y_train).detach().squeeze()

        # æ›´æ–°å…¨å±€è¯¯å·®è®°å½•
        model_errors = torch.cat((model_errors, batch_errors)) if model_errors.numel() > 0 else batch_errors

        # è®¡ç®—æŸå¤±
        loss = criterion(outputs, y_train, model_errors)

        # åå‘ä¼ æ’­
        loss.backward()
        optimizer.step()

        losses.append(loss.item())

        # æ›´æ–°è¿›åº¦
        if (epoch + 1) % 10 == 0 or epoch == epochs - 1:
            progress = (epoch + 1) / epochs
            progress_bar.progress(progress)
            status_text.text(f"Epoch [{epoch + 1}/{epochs}], Loss: {loss.item():.6f}")

    return model, losses


# è¯„ä¼°æ¨¡å‹
def evaluate_model(model, X_test, y_test, scaler, preprocessed_data):
    model.eval()
    with torch.no_grad():
        outputs = model(X_test)

    # åå½’ä¸€åŒ–å·®åˆ†å€¼
    def inverse_transform(data):
        return scaler.inverse_transform(data.numpy().reshape(-1, 1)).flatten()

    test_diff = inverse_transform(outputs)

    # é€†å·®åˆ†é‡å»ºåŸå§‹å€¼
    def reconstruct_original(diff_values, original_data, start_idx, d=1, D=1, s=12):
        reconstructed = []
        raw_history = list(original_data[start_idx - s - 1:start_idx])
        diff1_history = [raw_history[i] - raw_history[i - 1] for i in range(1, len(raw_history))]

        history_original = list(raw_history)
        history_diff1 = list(diff1_history)

        for i, val in enumerate(diff_values):
            diff1_current = val + history_diff1[-s]
            current_original = history_original[-1] + diff1_current
            reconstructed.append(current_original)

            history_original.pop(0)
            history_original.append(current_original)

            history_diff1.pop(0)
            history_diff1.append(diff1_current)

        return np.array(reconstructed)

    # é‡å»ºåŸå§‹æ•°æ®
    s = 12
    d = 1
    D = 1
    train_start_idx = s + 1 + preprocessed_data['p']
    test_start_idx = train_start_idx + preprocessed_data['train_size']

    test_reconstructed = reconstruct_original(test_diff, preprocessed_data['original'],
                                              test_start_idx, d, D, s)

    # è·å–å®é™…å€¼
    y_test_actual = preprocessed_data['original'][test_start_idx:test_start_idx + len(test_reconstructed)]

    # è®¡ç®—RMSE
    def rmse(actual, predicted):
        return np.sqrt(np.mean((actual - predicted) ** 2))

    test_rmse = rmse(y_test_actual, test_reconstructed)

    return {
        'predictions': test_reconstructed,
        'actuals': y_test_actual,
        'rmse': test_rmse,
        'test_start_idx': test_start_idx
    }


# é¢„æµ‹æœªæ¥
def forecast_future(model, last_values, months_ahead, month_features, p, q, scaler, original_data):
    forecast = []
    history = list(last_values)
    errors = [0] * q

    for i in range(months_ahead):
        ar_features = history[-p:]
        ma_features = errors[-q:]
        seasonal_feature = month_features[i]

        features = np.concatenate((ar_features, ma_features, seasonal_feature))
        features_tensor = torch.tensor(features, dtype=torch.float32).unsqueeze(0)

        with torch.no_grad():
            pred = model(features_tensor).item()

        forecast.append(pred)
        history.append(pred)
        errors.append(pred - np.mean(ar_features))

    # åå½’ä¸€åŒ–
    forecast = scaler.inverse_transform(np.array(forecast).reshape(-1, 1)).flatten()

    # é‡å»ºåŸå§‹å€¼
    s = 12
    last_original_values = original_data[-s - 1:]
    last_diff1_values = [last_original_values[i] - last_original_values[i - 1]
                         for i in range(1, len(last_original_values))]

    future_reconstructed = []
    history_original = list(last_original_values)
    history_diff1 = list(last_diff1_values)

    for val in forecast:
        diff1_current = val + history_diff1[-s]
        current_original = history_original[-1] + diff1_current
        future_reconstructed.append(current_original)

        history_original.pop(0)
        history_original.append(current_original)

        history_diff1.pop(0)
        history_diff1.append(diff1_current)

    return future_reconstructed


# ä¸»åº”ç”¨é€»è¾‘
if train_button:
    # é¢„å¤„ç†æ•°æ®
    with st.spinner("Preprocessing data..."):
        preprocessed_data = preprocess_data(passengers, months, p, q)

    # æ˜¾ç¤ºå·®åˆ†æ•°æ®
    if show_diff:
        st.subheader("Differenced Data")
        fig, ax = plt.subplots(figsize=(10, 4))
        diff_data = preprocessed_data['scaler'].transform(
            np.array(preprocessed_data['original'][13:]).reshape(-1, 1)
        ).flatten()
        ax.plot(preprocessed_data['months_diff'], diff_data)
        ax.set_title("Differenced Air Passengers Data")
        ax.set_xlabel("Month")
        ax.set_ylabel("Differenced Passengers")
        ax.grid(True)
        plt.xticks(rotation=45)
        st.pyplot(fig)

    # åˆå§‹åŒ–æ¨¡å‹
    input_size = p + q + 12
    model = ARIMAModel(input_size, hidden_size, 1)
    criterion = MALoss(q=q, alpha=alpha)
    optimizer = torch.optim.Adam(model.parameters(), lr=lr)

    # è®­ç»ƒæ¨¡å‹
    st.subheader("Model Training")
    model, losses = train_model(
        model,
        preprocessed_data['X_train'],
        preprocessed_data['y_train'],
        criterion,
        optimizer,
        epochs
    )

    # æ˜¾ç¤ºè®­ç»ƒæŸå¤±
    fig, ax = plt.subplots(figsize=(10, 4))
    ax.plot(losses)
    ax.set_title("Training Loss")
    ax.set_xlabel("Epoch")
    ax.set_ylabel("Loss")
    ax.grid(True)
    st.pyplot(fig)

    # è¯„ä¼°æ¨¡å‹
    with st.spinner("Evaluating model..."):
        results = evaluate_model(
            model,
            preprocessed_data['X_test'],
            preprocessed_data['y_test'],
            preprocessed_data['scaler'],
            preprocessed_data
        )

    # æ˜¾ç¤ºè¯„ä¼°ç»“æœ
    st.subheader("Model Evaluation")
    st.metric("Test RMSE", f"{results['rmse']:.2f}")
    st.metric("Test RMSE as % of mean",
              f"{results['rmse'] / np.mean(preprocessed_data['original']) * 100:.1f}%")

    # æ˜¾ç¤ºé¢„æµ‹ç»“æœ
    fig, ax = plt.subplots(figsize=(12, 6))

    # åŸå§‹æ•°æ®
    ax.plot(preprocessed_data['original'], 'b-', label='Historical Data', alpha=0.7)

    # æµ‹è¯•é›†é¢„æµ‹
    test_indices = range(results['test_start_idx'],
                         results['test_start_idx'] + len(results['predictions']))
    ax.plot(test_indices, results['predictions'], 'r-', label='Test Predictions', alpha=0.8)

    # æ·»åŠ æœ€å12ä¸ªæœˆä½œä¸ºå‚è€ƒ
    last_year_indices = range(len(preprocessed_data['original']) - 12,
                              len(preprocessed_data['original']))
    ax.plot(last_year_indices, preprocessed_data['original'][-12:], 'g-', alpha=0.7)

    ax.axvline(x=results['test_start_idx'], color='k', linestyle='--', label='Train/Test Split')
    ax.set_title("ARIMA Model Predictions with Seasonal Features")
    ax.set_xlabel("Time Steps")
    ax.set_ylabel("Passengers")
    ax.legend()
    ax.grid(True)
    st.pyplot(fig)

    # é¢„æµ‹æœªæ¥
    st.subheader(f"{forecast_months}-Month Forecast")

    # åˆ›å»ºæœˆä»½ç‰¹å¾
    last_month = int(data['Month'].iloc[-1].split('-')[1])
    future_months = [(last_month + i) % 12 or 12 for i in range(1, forecast_months + 1)]


    def create_month_features(months):
        month_features = np.zeros((len(months), 12))
        for i, month in enumerate(months):
            month_features[i, month - 1] = 1
        return month_features


    future_month_features = create_month_features(future_months)

    # è·å–æœ€åçš„å€¼
    last_diff1_values = [
                            passengers[-1] - passengers[-2],
                            passengers[-2] - passengers[-3]
                        ][-p:]

    # é¢„æµ‹
    with st.spinner("Generating forecast..."):
        future_reconstructed = forecast_future(
            model,
            last_diff1_values,
            forecast_months,
            future_month_features,
            p, q,
            preprocessed_data['scaler'],
            passengers
        )

    # æ˜¾ç¤ºé¢„æµ‹ç»“æœ
    fig, ax = plt.subplots(figsize=(12, 6))

    # åŸå§‹æ•°æ®
    ax.plot(preprocessed_data['original'], 'b-', label='Historical Data')

    # æœªæ¥é¢„æµ‹
    future_indices = range(len(preprocessed_data['original']),
                           len(preprocessed_data['original']) + len(future_reconstructed))
    ax.plot(future_indices, future_reconstructed, 'r--', label='Forecast')

    # æ·»åŠ æœ€å12ä¸ªæœˆä½œä¸ºå‚è€ƒ
    ax.plot(last_year_indices, preprocessed_data['original'][-12:], 'g-', alpha=0.7)

    ax.set_title(f"{forecast_months}-Month Forecast")
    ax.set_xlabel("Time Steps")
    ax.set_ylabel("Passengers")
    ax.legend()
    ax.grid(True)
    st.pyplot(fig)

    # æ˜¾ç¤ºé¢„æµ‹è¡¨æ ¼
    forecast_df = pd.DataFrame({
        'Month': [f"1961-{m:02d}" for m in future_months],
        'Forecasted Passengers': [int(round(x)) for x in future_reconstructed]
    })
    st.dataframe(forecast_df.style.format({"Forecasted Passengers": "{:,.0f}"}))

# æ·»åŠ è¯´æ˜
st.sidebar.markdown("""
**Model Notes:**
- This neural ARIMA model combines traditional time series concepts with deep learning
- AR (Autoregressive) component uses past observations
- MA (Moving Average) component models forecast errors
- Seasonal features are incorporated via month one-hot encoding
""")

# æ·»åŠ ä½œè€…ä¿¡æ¯
st.sidebar.markdown("---")
st.sidebar.info("""
**Developed by:** [Your Name]  
**Dataset:** Monthly Air Passengers (1949-1960)  
**Model:** Neural ARIMA with Seasonal Features
""")